{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2602adbc",
   "metadata": {},
   "source": [
    "# Machine Learning Classificaion model\n",
    "In this section we'll preprocess and build a classification model which will be able to classify Diabetic/Non-Diabetic by using the features within the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b66399",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09a07e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, confusion_matrix, accuracy_score,\n",
    "                             classification_report, f1_score, precision_score, recall_score)\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cfc50",
   "metadata": {},
   "source": [
    "## 2. Load & Quick sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3644b291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4105, 10), (1027, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------\n",
    "# Load data and check\n",
    "#---------------------\n",
    "\n",
    "data = pd.read_csv(\"../Data/train.csv\")\n",
    "test = pd.read_csv(\"../Data/test.csv\")\n",
    "\n",
    "data.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0580dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Fixed-----\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------\n",
    "# A quick fix (we know from EDA that Gender has F,f,M, values so we need to fix it)\n",
    "#-------------------------------------------\n",
    "\n",
    "# Replace `f` with `F`\n",
    "data[\"Gender\"] = data[\"Gender\"].replace(\"f\", \"F\")\n",
    "print(\"-----Fixed-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ea972b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check again\n",
    "(data[\"Gender\"] == \"f\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71de80",
   "metadata": {},
   "source": [
    "## 3. Split\n",
    "Split the data into train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20bb3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "\tx_train shape: (3284, 9)\n",
      "\tx_val shape: (821, 9)\n",
      "\ty_train shape: (3284,)\n",
      "\ty_val shape: (821,)\n",
      "\n",
      "-----Done-----\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------\n",
    "# Split Dataset into train and validation sets\n",
    "#----------------------------------------\n",
    "\n",
    "# Define random state\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Detemine target and features\n",
    "X = data.drop(columns=[\"Diagnosis\"], errors=\"ignore\")   # Features\n",
    "y = data[\"Diagnosis\"]   # Target\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "\n",
    "# Print Shapes\n",
    "print(f\"Shapes:\\n\\tx_train shape: {X_train.shape}\\n\\tx_val shape: {X_val.shape}\")\n",
    "print(f\"\\ty_train shape: {y_train.shape}\\n\\ty_val shape: {y_val.shape}\", end=\"\\n\\n\")\n",
    "print(\"-----Done-----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc96a9d",
   "metadata": {},
   "source": [
    "## 4. Preprocess\n",
    "- **Numeric columns:** impute (median), log1p for skewed features, scale.\n",
    "- **Categorical columns:** impute (most_frequent) + OneHotEncoder.\n",
    "- We'll include `FunctionTransformer(np.log1p)` only for selected skewed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Preprocessor was built-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocess:\n",
    "* Impute: When there is a missing value it works (just in case)\n",
    "* Scale: StandarScaler to standardize numeric features\n",
    "* log1p: log1p Transformation technique applied on the skewed features\n",
    "* Encode: OneHotEncoder for categorical features to be encoded \n",
    "\"\"\"\n",
    "\n",
    "# Identify columns\n",
    "#------------------\n",
    "\n",
    "# Numeric columns\n",
    "num_cols = [\"Age\", \"BMI\", \"Chol\", \"TG\", \"HDL\",\"LDL\", \"Cr\", \"BUN\"]\n",
    "# Categorical columns\n",
    "cat_col = [\"Gender\"]\n",
    "# Skewed/non-skewed (basic) columns\n",
    "skewed = [\"HDL\", \"TG\", \"BUN\"]\n",
    "non_skewed = [c for c in num_cols if c not in skewed]\n",
    "\n",
    "\n",
    "# Pipeline pieces\n",
    "#------------------\n",
    "\n",
    "# Skewed columns pipeline\n",
    "num_skewed_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log1p\", FunctionTransformer(np.log1p, validate=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Non-skewed (basic) columns pipeline\n",
    "num_basic_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical columns pipeline\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# Build Preprocessor \n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_skewed\", num_skewed_pipeline, skewed),\n",
    "    (\"num_basic\", num_basic_pipeline, non_skewed),\n",
    "    (\"cat\", cat_pipeline, cat_col)], remainder=\"drop\")\n",
    "\n",
    "print(\"-----Preprocessor was built-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed0886",
   "metadata": {},
   "source": [
    "## 5. Baseline models & Benchmarking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7903dcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1_weighted",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1_macro",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1_binary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a233ae18-0dfc-48c6-a6cd-70b3fc677eb8",
       "rows": [
        [
         "0",
         "SVC",
         "0.8443201471632763",
         "0.8342592636747592",
         "0.7914614121510674",
         "0.8453105968331304"
        ],
        [
         "1",
         "GradientBoosting",
         "0.8363330825022333",
         "0.8252232467983551",
         "0.7779632721202003",
         "0.8380024360535931"
        ],
        [
         "2",
         "GaussianProcess",
         "0.8342643012631642",
         "0.823338141651458",
         "0.7768595041322314",
         "0.8355663824604141"
        ],
        [
         "3",
         "RandomForest",
         "0.8331003271368196",
         "0.8221517132408221",
         "0.7755775577557755",
         "0.8343483556638246"
        ],
        [
         "4",
         "ExtraTrees",
         "0.8290868422495705",
         "0.8175966728523226",
         "0.7687188019966722",
         "0.830694275274056"
        ],
        [
         "5",
         "AdaBoost",
         "0.8247069373570749",
         "0.8133785409881147",
         "0.7651888341543513",
         "0.8258221680876979"
        ],
        [
         "6",
         "KNN",
         "0.8150307878367126",
         "0.8021724882411905",
         "0.7474747474747475",
         "0.8172959805115713"
        ],
        [
         "7",
         "LogisticRegression",
         "0.8141826726153175",
         "0.8015692501244485",
         "0.7479131886477463",
         "0.8160779537149817"
        ],
        [
         "8",
         "DecisionTree",
         "0.8023853751625857",
         "0.7918981751455918",
         "0.7472868217054264",
         "0.8014616321559074"
        ],
        [
         "9",
         "GaussianNB",
         "0.8007785880380277",
         "0.784019314019314",
         "0.7127272727272728",
         "0.807551766138855"
        ],
        [
         "10",
         "BernoulliNB",
         "0.7879399482412637",
         "0.7768207342741529",
         "0.7295208655332303",
         "0.7868453105968332"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>F1_binary</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.844320</td>\n",
       "      <td>0.834259</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.845311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.836333</td>\n",
       "      <td>0.825223</td>\n",
       "      <td>0.777963</td>\n",
       "      <td>0.838002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianProcess</td>\n",
       "      <td>0.834264</td>\n",
       "      <td>0.823338</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.835566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.833100</td>\n",
       "      <td>0.822152</td>\n",
       "      <td>0.775578</td>\n",
       "      <td>0.834348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.829087</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.768719</td>\n",
       "      <td>0.830694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.824707</td>\n",
       "      <td>0.813379</td>\n",
       "      <td>0.765189</td>\n",
       "      <td>0.825822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.802172</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.817296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.814183</td>\n",
       "      <td>0.801569</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.816078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.802385</td>\n",
       "      <td>0.791898</td>\n",
       "      <td>0.747287</td>\n",
       "      <td>0.801462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.800779</td>\n",
       "      <td>0.784019</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>0.807552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.787940</td>\n",
       "      <td>0.776821</td>\n",
       "      <td>0.729521</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1_weighted  F1_macro  F1_binary  Accuracy\n",
       "0                  SVC     0.844320  0.834259   0.791461  0.845311\n",
       "1     GradientBoosting     0.836333  0.825223   0.777963  0.838002\n",
       "2      GaussianProcess     0.834264  0.823338   0.776860  0.835566\n",
       "3         RandomForest     0.833100  0.822152   0.775578  0.834348\n",
       "4           ExtraTrees     0.829087  0.817597   0.768719  0.830694\n",
       "5             AdaBoost     0.824707  0.813379   0.765189  0.825822\n",
       "6                  KNN     0.815031  0.802172   0.747475  0.817296\n",
       "7   LogisticRegression     0.814183  0.801569   0.747913  0.816078\n",
       "8         DecisionTree     0.802385  0.791898   0.747287  0.801462\n",
       "9           GaussianNB     0.800779  0.784019   0.712727  0.807552\n",
       "10         BernoulliNB     0.787940  0.776821   0.729521  0.786845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check all the models possible to be used for the project,\n",
    "then FIT, TRAIN, and EVALUATE to see their performances and benchmark.\n",
    "* Strong cnadidates will be considered for optimization.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(random_state=RANDOM_STATE),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"SVC\": SVC(probability=True, random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"GaussianProcess\": GaussianProcessClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# Train & Evaluate each model and store them in `results`\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"pre\", preprocessor), (\"clf\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"F1_weighted\": f1_score(y_val, y_pred, average='weighted', zero_division=0),\n",
    "        \"F1_macro\": f1_score(y_val, y_pred, average='macro', zero_division=0),\n",
    "        \"F1_binary\": f1_score(y_val, y_pred, average='binary', zero_division=0),\n",
    "        \"Accuracy\": accuracy_score(y_val, y_pred)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by one or more metrics -> Primary metric: F1 score weighted\n",
    "results_df = results_df.sort_values(by='F1_weighted', ascending=False).reset_index(drop=True)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a2a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1_str",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AUC_str",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUC_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUC_std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9e3bd69b-cd5d-48db-a634-1eb35bb50920",
       "rows": [
        [
         "0",
         "SVC",
         "0.826 ± 0.011",
         "0.899 ± 0.008",
         "0.8258447727148234",
         "0.010604028529979707",
         "0.8987663740895513",
         "0.008450000076265847"
        ],
        [
         "1",
         "ExtraTrees",
         "0.825 ± 0.010",
         "0.907 ± 0.008",
         "0.8245748875243792",
         "0.009604896100458199",
         "0.9072661921122229",
         "0.007742545412177135"
        ],
        [
         "2",
         "GaussianProcess",
         "0.822 ± 0.009",
         "0.894 ± 0.007",
         "0.8221998718900544",
         "0.008585713092358475",
         "0.8944673841680452",
         "0.006520761919360385"
        ],
        [
         "3",
         "GradientBoosting",
         "0.819 ± 0.012",
         "0.911 ± 0.011",
         "0.8186643754502697",
         "0.01178580136016293",
         "0.9107328482363464",
         "0.011031205718295493"
        ],
        [
         "4",
         "RandomForest",
         "0.817 ± 0.013",
         "0.907 ± 0.007",
         "0.8167173779052004",
         "0.013029746786828831",
         "0.9074299050764582",
         "0.00727314652535515"
        ],
        [
         "5",
         "AdaBoost",
         "0.814 ± 0.018",
         "0.902 ± 0.011",
         "0.8139237471971377",
         "0.017808815722120258",
         "0.9016751398724401",
         "0.010768011317784217"
        ],
        [
         "6",
         "LogisticRegression",
         "0.810 ± 0.016",
         "0.886 ± 0.011",
         "0.8102170283236507",
         "0.01590917898207046",
         "0.8859771326419675",
         "0.010792570670852077"
        ],
        [
         "7",
         "KNN",
         "0.800 ± 0.008",
         "0.869 ± 0.011",
         "0.800097392452398",
         "0.007834202554432219",
         "0.8692607361845098",
         "0.011217969204710753"
        ],
        [
         "8",
         "GaussianNB",
         "0.782 ± 0.010",
         "0.882 ± 0.006",
         "0.7820871677068004",
         "0.009720462364018386",
         "0.8824738831775818",
         "0.006014084769490505"
        ],
        [
         "9",
         "BernoulliNB",
         "0.780 ± 0.005",
         "0.845 ± 0.012",
         "0.7798531664852179",
         "0.004671617013169144",
         "0.8450622712714321",
         "0.011890272236112233"
        ],
        [
         "10",
         "DecisionTree",
         "0.772 ± 0.017",
         "0.758 ± 0.016",
         "0.7717724043495777",
         "0.017374702409434468",
         "0.7582061766920035",
         "0.01579634173168786"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_str</th>\n",
       "      <th>AUC_str</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>AUC_mean</th>\n",
       "      <th>AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.826 ± 0.011</td>\n",
       "      <td>0.899 ± 0.008</td>\n",
       "      <td>0.825845</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.898766</td>\n",
       "      <td>0.008450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.825 ± 0.010</td>\n",
       "      <td>0.907 ± 0.008</td>\n",
       "      <td>0.824575</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.907266</td>\n",
       "      <td>0.007743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianProcess</td>\n",
       "      <td>0.822 ± 0.009</td>\n",
       "      <td>0.894 ± 0.007</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.819 ± 0.012</td>\n",
       "      <td>0.911 ± 0.011</td>\n",
       "      <td>0.818664</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.910733</td>\n",
       "      <td>0.011031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.817 ± 0.013</td>\n",
       "      <td>0.907 ± 0.007</td>\n",
       "      <td>0.816717</td>\n",
       "      <td>0.013030</td>\n",
       "      <td>0.907430</td>\n",
       "      <td>0.007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.814 ± 0.018</td>\n",
       "      <td>0.902 ± 0.011</td>\n",
       "      <td>0.813924</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.901675</td>\n",
       "      <td>0.010768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.810 ± 0.016</td>\n",
       "      <td>0.886 ± 0.011</td>\n",
       "      <td>0.810217</td>\n",
       "      <td>0.015909</td>\n",
       "      <td>0.885977</td>\n",
       "      <td>0.010793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.800 ± 0.008</td>\n",
       "      <td>0.869 ± 0.011</td>\n",
       "      <td>0.800097</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.869261</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.782 ± 0.010</td>\n",
       "      <td>0.882 ± 0.006</td>\n",
       "      <td>0.782087</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.882474</td>\n",
       "      <td>0.006014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.780 ± 0.005</td>\n",
       "      <td>0.845 ± 0.012</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.845062</td>\n",
       "      <td>0.011890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.772 ± 0.017</td>\n",
       "      <td>0.758 ± 0.016</td>\n",
       "      <td>0.771772</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.758206</td>\n",
       "      <td>0.015796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model         F1_str        AUC_str   F1_mean    F1_std  \\\n",
       "0                  SVC  0.826 ± 0.011  0.899 ± 0.008  0.825845  0.010604   \n",
       "1           ExtraTrees  0.825 ± 0.010  0.907 ± 0.008  0.824575  0.009605   \n",
       "2      GaussianProcess  0.822 ± 0.009  0.894 ± 0.007  0.822200  0.008586   \n",
       "3     GradientBoosting  0.819 ± 0.012  0.911 ± 0.011  0.818664  0.011786   \n",
       "4         RandomForest  0.817 ± 0.013  0.907 ± 0.007  0.816717  0.013030   \n",
       "5             AdaBoost  0.814 ± 0.018  0.902 ± 0.011  0.813924  0.017809   \n",
       "6   LogisticRegression  0.810 ± 0.016  0.886 ± 0.011  0.810217  0.015909   \n",
       "7                  KNN  0.800 ± 0.008  0.869 ± 0.011  0.800097  0.007834   \n",
       "8           GaussianNB  0.782 ± 0.010  0.882 ± 0.006  0.782087  0.009720   \n",
       "9          BernoulliNB  0.780 ± 0.005  0.845 ± 0.012  0.779853  0.004672   \n",
       "10        DecisionTree  0.772 ± 0.017  0.758 ± 0.016  0.771772  0.017375   \n",
       "\n",
       "    AUC_mean   AUC_std  \n",
       "0   0.898766  0.008450  \n",
       "1   0.907266  0.007743  \n",
       "2   0.894467  0.006521  \n",
       "3   0.910733  0.011031  \n",
       "4   0.907430  0.007273  \n",
       "5   0.901675  0.010768  \n",
       "6   0.885977  0.010793  \n",
       "7   0.869261  0.011218  \n",
       "8   0.882474  0.006014  \n",
       "9   0.845062  0.011890  \n",
       "10  0.758206  0.015796  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use K-folds\n",
    "#-------------------\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "results = []\n",
    "for name, base_model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"pre\", preprocessor), (\"clf\", base_model)])\n",
    "    # F1-weighted\n",
    "    f1_scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "    # ROC-AUC (requires predict_proba or decision_function; will error for some models like KNN? usually OK)\n",
    "    try:\n",
    "        auc_scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    except Exception:\n",
    "        auc_scores = np.array([np.nan]*cv.get_n_splits())\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"F1_mean\": f1_scores.mean(),\n",
    "        \"F1_std\": f1_scores.std(),\n",
    "        \"AUC_mean\": np.nanmean(auc_scores),\n",
    "        \"AUC_std\": np.nanstd(auc_scores)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='F1_mean', ascending=False).reset_index(drop=True)\n",
    "results_df['F1_str'] = results_df.apply(lambda r: f\"{r['F1_mean']:.3f} ± {r['F1_std']:.3f}\", axis=1)\n",
    "results_df['AUC_str'] = results_df.apply(lambda r: (f\"{r['AUC_mean']:.3f} ± {r['AUC_std']:.3f}\"\n",
    "                                                   if not np.isnan(r['AUC_mean']) else \"n/a\"), axis=1)\n",
    "results_df = results_df[[\"Model\",\"F1_str\",\"AUC_str\",\"F1_mean\",\"F1_std\",\"AUC_mean\",\"AUC_std\"]]\n",
    "\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
